{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Layers' from '/Users/chris/Desktop/Georgia Tech/RoboticMusicianship/RoboticMusicianship/Layers.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our functions\n",
    "import importlib\n",
    "from LoadingPieces import *\n",
    "importlib.reload(LoadingPieces)\n",
    "\n",
    "import Layers\n",
    "importlib.reload(Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chris/Desktop/Georgia Tech/RoboticMusicianship/RoboticMusicianship/MIDI_Files/Piano_Midi/beeth\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'load_pieces' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c26571da6606>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mcurr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmusic_directory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mMIDI_Directories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtraining_pieces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_pieces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Set aside random set of pieces for validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_pieces' is not defined"
     ]
    }
   ],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set the current directory\n",
    "directory = os.getcwd()\n",
    "\n",
    "# Set the directory to all the music files\n",
    "music_directory = directory + \"/MIDI_Files/Piano_Midi/\"\n",
    "\n",
    "# Load all the files from the music directories\n",
    "# MIDI_Directories = [\"albeniz\", \"beeth\", \"borodin\", \"brahms\", \"burgm\", \"Chopin\", \"debussy\", \"granados\", \"grieg\", \"haydn\", \"liszt\", \"mendelssohn\", \"mozart\", \"muss\", \"schubert\", \"schumann\", \"tschai\"]\n",
    "MIDI_Directories = [\"beeth\"]\n",
    "training_pieces = {}\n",
    "for i in range(len(MIDI_Directories)):\n",
    "    curr = music_directory + MIDI_Directories[i]\n",
    "    print(curr)\n",
    "    training_pieces.update(load_pieces(curr))\n",
    "\n",
    "# Set aside random set of pieces for validation set\n",
    "validation_count = 0\n",
    "validation_set = {}\n",
    "for i in range(validation_count):\n",
    "    random_key = random.choice(list(training_pieces.keys()))\n",
    "    validation_set[random_key] = training_pieces.pop(random_key)\n",
    "\n",
    "print(list(training_pieces.keys()))\n",
    "print(list(validation_set.keys()))\n",
    "\n",
    "batch_size = 15\n",
    "time_steps = 128\n",
    "# Call Get Piece Batch\n",
    "_, sample_state = get_piece_batch(training_pieces, batch_size, time_steps)\n",
    "sample_state = np.array(sample_state)\n",
    "sample_state = np.swapaxes(sample_state, axis1=1, axis2=2)\n",
    "print('State Input Batch Shape = ', sample_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin building the model graph for training\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# Capture the number of notes from the sample\n",
    "num_notes = sample_state.shape[1]\n",
    "\n",
    "# Placeholders for the graph input\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "note_state_batch = tf.compat.v1.placeholder(dtype=tf.float32, shape=[None, num_notes, None, 2])\n",
    "initial_time = tf.compat.v1.placeholder(dtype=tf.int32, shape=())\n",
    "\n",
    "# Generate expanded tensor from the batch of note state matrices\n",
    "note_state_expand = input_kernel(note_state_batch, midi_low=24, midi_high=101, time_init=initial_time)\n",
    "print(\"Note State Expand Shape: \", note_state_expand.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Time Wise Training Graph\n",
    "num_t_units = [200, 200]\n",
    "output_keep_prob = tf.compat.v1.placeholder(dtype=tf.float32, shape=())\n",
    "\n",
    "# Generate Initial State (at t = 0) placeholder\n",
    "timewise_state = []\n",
    "for i in range(len(num_t_units)):\n",
    "    timewise_c = tf.compat.v1.placeholder(dtype=tf.float32, shape=[None, num_t_units[i]]) # None = batch_size * num_notes\n",
    "    timewise_h = tf.compat.v1.placeholder(dtype=tf.float32, shape=[None, num_t_units[i]])\n",
    "    timewise_state.append(tf.compat.v1.nn.rnn_cell.LSTMStateTuple(timewise_h, timewise_c))\n",
    "\n",
    "timewise_state = tuple(timewise_state)\n",
    "\n",
    "timewise_out, timewise_state_out = lstm_timewise_training_layer(input_data=note_state_expand, state_init=timewise_state, output_keep_prob=output_keep_prob)\n",
    "print(\"Time-wise output shape = \", timewise_out.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Note Wise Training Graph\n",
    "num_n_units = [100, 100]\n",
    "\n",
    "# Generate Initial State (at n = 0) placeholder\n",
    "notewise_state = []\n",
    "for i in range(len(num_n_units)):\n",
    "    notewise_c = tf.compat.v1.placeholder(dtype=tf.float32, shape=[None, num_n_units[i]]) # None = batch_size * num_timesteps\n",
    "    notewise_h = tf.compat.v1.placeholder(dtype=tf.float32, shape=[None, num_n_units[i]])\n",
    "    notewise_state.append(tf.compat.v1.nn.rnn_cell.LSTMStateTuple(notewise_h, notewise_c))\n",
    "\n",
    "notewise_state = tuple(notewise_state)\n",
    "\n",
    "y_out, note_gen_out = lstm_notewise_layer(timewise_out, state_init=notewise_state, output_keep_prob=output_keep_prob)\n",
    "p_out = tf.sigmoid(y_out)\n",
    "print(\"y_out shape = \", y_out.get_shape())\n",
    "print(\"Generated samples shape = \", note_gen_out.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
